# Data Engineering project End to End on Microsift Azure.
## This projects includes data extraction, transformation using microsoft azure services.

## Steps included:
 1. Extracting data from folder using API.
 2. Creating container in storage.
 3. Created data piplines in Data Factory to load data extracted into Data lake Gen2.
 4. Created Databrick account and transformed data using pyspark.
 5. Loaded transformed data into DataLake Gen 2. 
 7. Connected to Tableau to visualise data of olympics.

## Services used and learnt:
1. DataFactory
2. DataLakeGen2
3. Storage(container)
4. App Registration(secret key creation)
5. Key Vault
6. IAM role creation to provide access to storage
7. Azure Synapse.
8. Tableau
9. Git

## Piplines in Data Factory
![image](https://github.com/Aishwaryasjsu/DE_Piplineonazure/assets/111553278/f60c188f-d8e5-4f9b-bd8f-111e42e8ea0a)

